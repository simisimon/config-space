mapreduce.jobtracker.jobhistory.location=
mapreduce.jobtracker.jobhistory.task.numberprogresssplits=12
mapreduce.job.userhistorylocation=
mapreduce.jobtracker.jobhistory.completed.location=
mapreduce.job.committer.setup.cleanup.needed=true
mapreduce.task.io.sort.factor=10
mapreduce.task.io.sort.mb=100
mapreduce.map.sort.spill.percent=0.80
mapreduce.jobtracker.address=local
mapreduce.local.clientfactory.class.name=org.apache.hadoop.mapred.LocalClientFactory
mapreduce.jobtracker.http.address=0.0.0.0:50030
mapreduce.jobtracker.handler.count=10
mapreduce.tasktracker.report.address=127.0.0.1:0
mapreduce.cluster.local.dir=${hadoop.tmp.dir}/mapred/local
mapreduce.jobtracker.system.dir=${hadoop.tmp.dir}/mapred/system
mapreduce.jobtracker.staging.root.dir=${hadoop.tmp.dir}/mapred/staging
mapreduce.cluster.temp.dir=${hadoop.tmp.dir}/mapred/temp
mapreduce.tasktracker.local.dir.minspacestart=0
mapreduce.tasktracker.local.dir.minspacekill=0
mapreduce.jobtracker.expire.trackers.interval=600000
mapreduce.tasktracker.instrumentation=org.apache.hadoop.mapred.TaskTrackerMetricsInst
mapreduce.tasktracker.resourcecalculatorplugin=
mapreduce.tasktracker.taskmemorymanager.monitoringinterval=5000
mapreduce.tasktracker.tasks.sleeptimebeforesigkill=5000
mapreduce.job.maps=2
mapreduce.job.reduces=1
mapreduce.jobtracker.restart.recover=false
mapreduce.jobtracker.jobhistory.block.size=3145728
mapreduce.jobtracker.taskscheduler=org.apache.hadoop.mapred.JobQueueTaskScheduler
mapreduce.job.running.map.limit=0
mapreduce.job.running.reduce.limit=0
mapreduce.job.reducer.preempt.delay.sec=0
mapreduce.job.max.split.locations=10
mapreduce.job.split.metainfo.maxsize=10000000
mapreduce.jobtracker.taskscheduler.maxrunningtasks.perjob=
mapreduce.map.maxattempts=4
mapreduce.reduce.maxattempts=4
mapreduce.reduce.shuffle.fetch.retry.enabled=${yarn.nodemanager.recovery.enabled}
mapreduce.reduce.shuffle.fetch.retry.interval-ms=1000
mapreduce.reduce.shuffle.fetch.retry.timeout-ms=30000
mapreduce.reduce.shuffle.retry-delay.max.ms=60000
mapreduce.reduce.shuffle.parallelcopies=5
mapreduce.reduce.shuffle.connect.timeout=180000
mapreduce.reduce.shuffle.read.timeout=180000
mapreduce.shuffle.connection-keep-alive.enable=false
mapreduce.shuffle.connection-keep-alive.timeout=5
mapreduce.task.timeout=600000
mapreduce.tasktracker.map.tasks.maximum=2
mapreduce.tasktracker.reduce.tasks.maximum=2
mapreduce.map.memory.mb=1024
mapreduce.map.cpu.vcores=1
mapreduce.reduce.memory.mb=1024
mapreduce.reduce.cpu.vcores=1
mapreduce.jobtracker.retiredjobs.cache.size=1000
mapreduce.tasktracker.outofband.heartbeat=false
mapreduce.jobtracker.jobhistory.lru.cache.size=5
mapreduce.jobtracker.instrumentation=org.apache.hadoop.mapred.JobTrackerMetricsInst
mapred.child.java.opts=-Xmx200m
mapred.child.env=
mapreduce.admin.user.env=
mapreduce.map.log.level=INFO
mapreduce.reduce.log.level=INFO
mapreduce.map.cpu.vcores=1
mapreduce.reduce.cpu.vcores=1
mapreduce.reduce.merge.inmem.threshold=1000
mapreduce.reduce.shuffle.merge.percent=0.66
mapreduce.reduce.shuffle.input.buffer.percent=0.70
mapreduce.reduce.input.buffer.percent=0.0
mapreduce.reduce.shuffle.memory.limit.percent=0.25
mapreduce.shuffle.ssl.enabled=false
mapreduce.shuffle.ssl.file.buffer.size=65536
mapreduce.shuffle.max.connections=0
mapreduce.shuffle.max.threads=0
mapreduce.shuffle.transferTo.allowed=
mapreduce.shuffle.transfer.buffer.size=131072
mapreduce.reduce.markreset.buffer.percent=0.0
mapreduce.map.speculative=true
mapreduce.reduce.speculative=true
mapreduce.job.speculative.speculative-cap-running-tasks=0.1
mapreduce.job.speculative.speculative-cap-total-tasks=0.01
mapreduce.job.speculative.minimum-allowed-tasks=10
mapreduce.job.speculative.retry-after-no-speculate=1000
mapreduce.job.speculative.retry-after-speculate=15000
mapreduce.job.map.output.collector.class=org.apache.hadoop.mapred.MapTask$MapOutputBuffer
mapreduce.job.speculative.slowtaskthreshold=1.0
mapreduce.job.jvm.numtasks=1
mapreduce.job.ubertask.enable=false
mapreduce.job.ubertask.maxmaps=9
mapreduce.job.ubertask.maxreduces=1
mapreduce.job.ubertask.maxbytes=
mapreduce.job.emit-timeline-data=false
mapreduce.input.fileinputformat.split.minsize=0
mapreduce.input.fileinputformat.list-status.num-threads=1
mapreduce.jobtracker.maxtasks.perjob=-1
mapreduce.input.lineinputformat.linespermap=1
mapreduce.client.submit.file.replication=10
mapreduce.tasktracker.dns.interface=default
mapreduce.tasktracker.dns.nameserver=default
mapreduce.tasktracker.http.threads=40
mapreduce.tasktracker.http.address=0.0.0.0:50060
mapreduce.task.files.preserve.failedtasks=false
mapreduce.output.fileoutputformat.compress=false
mapreduce.output.fileoutputformat.compress.type=RECORD
mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.DefaultCodec
mapreduce.map.output.compress=false
mapreduce.map.output.compress.codec=org.apache.hadoop.io.compress.DefaultCodec
map.sort.class=org.apache.hadoop.util.QuickSort
mapreduce.task.userlog.limit.kb=0
yarn.app.mapreduce.am.container.log.limit.kb=0
yarn.app.mapreduce.task.container.log.backups=0
yarn.app.mapreduce.am.container.log.backups=0
yarn.app.mapreduce.shuffle.log.separate=true
yarn.app.mapreduce.shuffle.log.limit.kb=0
yarn.app.mapreduce.shuffle.log.backups=0
mapreduce.job.userlog.retain.hours=24
mapreduce.jobtracker.hosts.filename=
mapreduce.jobtracker.hosts.exclude.filename=
mapreduce.jobtracker.heartbeats.in.second=100
mapreduce.jobtracker.tasktracker.maxblacklists=4
mapreduce.job.maxtaskfailures.per.tracker=3
mapreduce.client.output.filter=FAILED
mapreduce.client.completion.pollinterval=5000
mapreduce.client.progressmonitor.pollinterval=1000
mapreduce.jobtracker.persist.jobstatus.active=true
mapreduce.jobtracker.persist.jobstatus.hours=1
mapreduce.jobtracker.persist.jobstatus.dir=/jobtracker/jobsInfo
mapreduce.task.profile=false
mapreduce.task.profile.maps=0-2
mapreduce.task.profile.reduces=0-2
mapreduce.task.profile.params=-agentlib:hprof=cpu=samples,heap=sites,force=n,thread=y,verbose=n,file=%s
mapreduce.task.profile.map.params=${mapreduce.task.profile.params}
mapreduce.task.profile.reduce.params=${mapreduce.task.profile.params}
mapreduce.task.skip.start.attempts=2
mapreduce.map.skip.proc.count.autoincr=true
mapreduce.reduce.skip.proc.count.autoincr=true
mapreduce.job.skip.outdir=
mapreduce.map.skip.maxrecords=0
mapreduce.reduce.skip.maxgroups=0
mapreduce.ifile.readahead=true
mapreduce.ifile.readahead.bytes=4194304
mapreduce.jobtracker.taskcache.levels=2
mapreduce.job.queuename=default
mapreduce.job.tags=
mapreduce.cluster.acls.enabled=false
mapreduce.job.acl-modify-job=
mapreduce.job.acl-view-job=
mapreduce.tasktracker.indexcache.mb=10
mapreduce.job.token.tracking.ids.enabled=false
mapreduce.job.token.tracking.ids=
mapreduce.task.merge.progress.records=10000
mapreduce.task.combine.progress.records=10000
mapreduce.job.reduce.slowstart.completedmaps=0.05
mapreduce.job.complete.cancel.delegation.tokens=true
mapreduce.tasktracker.taskcontroller=org.apache.hadoop.mapred.DefaultTaskController
mapreduce.tasktracker.group=
mapreduce.shuffle.port=13562
mapreduce.job.reduce.shuffle.consumer.plugin.class=org.apache.hadoop.mapreduce.task.reduce.Shuffle
mapreduce.tasktracker.healthchecker.script.path=
mapreduce.tasktracker.healthchecker.interval=60000
mapreduce.tasktracker.healthchecker.script.timeout=600000
mapreduce.tasktracker.healthchecker.script.args=
mapreduce.job.counters.limit=120
mapreduce.framework.name=local
yarn.app.mapreduce.am.staging-dir=/tmp/hadoop-yarn/staging
mapreduce.am.max-attempts=2
mapreduce.job.end-notification.url=
mapreduce.job.end-notification.retry.attempts=0
mapreduce.job.end-notification.retry.interval=1000
mapreduce.job.end-notification.max.attempts=5
mapreduce.job.log4j-properties-file=
mapreduce.job.end-notification.max.retry.interval=5000
yarn.app.mapreduce.am.env=
yarn.app.mapreduce.am.admin.user.env=
yarn.app.mapreduce.am.command-opts=-Xmx1024m
yarn.app.mapreduce.am.admin-command-opts=
yarn.app.mapreduce.am.job.task.listener.thread-count=30
yarn.app.mapreduce.am.job.client.port-range=
yarn.app.mapreduce.am.job.committer.cancel-timeout=60000
yarn.app.mapreduce.am.job.committer.commit-window=10000
mapreduce.fileoutputcommitter.algorithm.version=1
yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms=1000
yarn.app.mapreduce.client-am.ipc.max-retries=3
yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts=3
yarn.app.mapreduce.client.max-retries=3
yarn.app.mapreduce.am.resource.mb=1536
yarn.app.mapreduce.am.resource.cpu-vcores=1
yarn.app.mapreduce.am.hard-kill-timeout-ms=10000
yarn.app.mapreduce.client.job.max-retries=0
yarn.app.mapreduce.client.job.retry-interval=2000
mapreduce.application.classpath=
mapreduce.app-submission.cross-platform=false
mapreduce.application.framework.path=
mapreduce.job.classloader=false
mapreduce.job.classloader.system.classes=
mapreduce.jobhistory.address=0.0.0.0:10020
mapreduce.jobhistory.webapp.address=0.0.0.0:19888
mapreduce.jobhistory.keytab=/etc/security/keytab/jhs.service.keytab
mapreduce.jobhistory.principal=jhs/_HOST@REALM.TLD
mapreduce.jobhistory.intermediate-done-dir=${yarn.app.mapreduce.am.staging-dir}/history/done_intermediate
mapreduce.jobhistory.done-dir=${yarn.app.mapreduce.am.staging-dir}/history/done
mapreduce.jobhistory.cleaner.enable=true
mapreduce.jobhistory.cleaner.interval-ms=86400000
mapreduce.jobhistory.max-age-ms=604800000
mapreduce.jobhistory.client.thread-count=10
mapreduce.jobhistory.datestring.cache.size=200000
mapreduce.jobhistory.joblist.cache.size=20000
mapreduce.jobhistory.loadedjobs.cache.size=5
mapreduce.jobhistory.move.interval-ms=180000
mapreduce.jobhistory.move.thread-count=3
mapreduce.jobhistory.store.class=
mapreduce.jobhistory.minicluster.fixed.ports=false
mapreduce.jobhistory.admin.address=0.0.0.0:10033
mapreduce.jobhistory.admin.acl=*
mapreduce.jobhistory.recovery.enable=false
mapreduce.jobhistory.recovery.store.class=org.apache.hadoop.mapreduce.v2.hs.HistoryServerFileSystemStateStoreService
mapreduce.jobhistory.recovery.store.fs.uri=${hadoop.tmp.dir}/mapred/history/recoverystore
mapreduce.jobhistory.recovery.store.leveldb.path=${hadoop.tmp.dir}/mapred/history/recoverystore
mapreduce.jobhistory.http.policy=HTTP_ONLY
yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size=10
