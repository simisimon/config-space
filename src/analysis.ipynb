{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of commits: 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Returned to the latest commit: 643b6134b92bfec74c822d0436fc7c57ded16935\n",
      "{'author': 'Sebastian Simon <Bastisimon95@googlemail.com>',\n",
      " 'commit_hash': '643b6134b92bfec74c822d0436fc7c57ded16935',\n",
      " 'commit_mgs': 'Initial commit\\n',\n",
      " 'deletions': 0,\n",
      " 'files_changed': 2,\n",
      " 'insertions': 86,\n",
      " 'network_data': {'concepts': {'docker', 'maven'},\n",
      "                  'config_files': {'src/Dockerfile', 'src/pom.xml'},\n",
      "                  'config_files_data': [{'deletions': 0,\n",
      "                                         'file_path': 'src/Dockerfile',\n",
      "                                         'insertions': 24,\n",
      "                                         'options': 18,\n",
      "                                         'total_changes': 24},\n",
      "                                        {'deletions': 0,\n",
      "                                         'file_path': 'src/pom.xml',\n",
      "                                         'insertions': 62,\n",
      "                                         'options': 27,\n",
      "                                         'total_changes': 62}],\n",
      "                  'links': 15}}\n",
      "{'author': 'Sebastian Simon <Bastisimon95@googlemail.com>',\n",
      " 'commit_hash': '318d7c429417df2861637b77ca6db6eed94b2fa8',\n",
      " 'commit_mgs': 'Add docker compose file\\n',\n",
      " 'deletions': 0,\n",
      " 'files_changed': 1,\n",
      " 'insertions': 13,\n",
      " 'network_data': {'concepts': {'docker-compose', 'docker', 'maven'},\n",
      "                  'config_files': {'src/Dockerfile',\n",
      "                                   'src/docker-compose.yml',\n",
      "                                   'src/pom.xml'},\n",
      "                  'config_files_data': [{'file_path': 'src/Dockerfile',\n",
      "                                         'options': 18},\n",
      "                                        {'deletions': 0,\n",
      "                                         'file_path': 'src/docker-compose.yml',\n",
      "                                         'insertions': 13,\n",
      "                                         'options': 8,\n",
      "                                         'total_changes': 13},\n",
      "                                        {'file_path': 'src/pom.xml',\n",
      "                                         'options': 27}],\n",
      "                  'links': 18}}\n",
      "{'author': 'Sebastian Simon <Bastisimon95@googlemail.com>',\n",
      " 'commit_hash': 'fd4226690c2aa81d6622cecb9985eb2c48d2ef7e',\n",
      " 'commit_mgs': 'Remove dependencies in pom.xml\\n',\n",
      " 'deletions': 20,\n",
      " 'files_changed': 1,\n",
      " 'insertions': 0,\n",
      " 'network_data': {'concepts': {'docker-compose', 'docker', 'maven'},\n",
      "                  'config_files': {'src/Dockerfile',\n",
      "                                   'src/docker-compose.yml',\n",
      "                                   'src/pom.xml'},\n",
      "                  'config_files_data': [{'file_path': 'src/Dockerfile',\n",
      "                                         'options': 18},\n",
      "                                        {'file_path': 'src/docker-compose.yml',\n",
      "                                         'options': 8},\n",
      "                                        {'deletions': 20,\n",
      "                                         'file_path': 'src/pom.xml',\n",
      "                                         'insertions': 0,\n",
      "                                         'options': 19,\n",
      "                                         'total_changes': 20}],\n",
      "                  'links': 11}}\n",
      "{'author': 'Sebastian Simon <Bastisimon95@googlemail.com>',\n",
      " 'commit_hash': '89ae70a2e00b19962f8cadd444c483545425b3df',\n",
      " 'commit_mgs': 'Add config file\\n',\n",
      " 'deletions': 0,\n",
      " 'files_changed': 1,\n",
      " 'insertions': 58,\n",
      " 'network_data': {'concepts': {'docker-compose', 'docker', 'maven'},\n",
      "                  'config_files': {'src/Dockerfile',\n",
      "                                   'src/docker-compose.yml',\n",
      "                                   'src/pom.xml'},\n",
      "                  'config_files_data': [{'file_path': 'src/Dockerfile',\n",
      "                                         'options': 18},\n",
      "                                        {'file_path': 'src/docker-compose.yml',\n",
      "                                         'options': 8},\n",
      "                                        {'file_path': 'src/pom.xml',\n",
      "                                         'options': 19}],\n",
      "                  'links': 11}}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type set is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 154\u001b[0m\n\u001b[1;32m    150\u001b[0m         json\u001b[38;5;241m.\u001b[39mdump(commit_data, dest, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    152\u001b[0m test_repo_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/ssimon/github/config_project\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 154\u001b[0m stats \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_repository\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_repo_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbranch_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaster\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 150\u001b[0m, in \u001b[0;36manalyze_repository\u001b[0;34m(repo_path, branch_name)\u001b[0m\n\u001b[1;32m    147\u001b[0m     pprint(x)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/test_project_data.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m dest:\n\u001b[0;32m--> 150\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommit_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[1;32m    174\u001b[0m         check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[1;32m    175\u001b[0m         separators\u001b[38;5;241m=\u001b[39mseparators,\n\u001b[1;32m    176\u001b[0m         default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39miterencode(obj)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m    180\u001b[0m     fp\u001b[38;5;241m.\u001b[39mwrite(chunk)\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/encoder.py:429\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m _floatstr(o)\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 429\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/encoder.py:325\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 325\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    327\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 405\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 405\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/encoder.py:438\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    437\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[0;32m--> 438\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    180\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type set is not JSON serializable"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import git\n",
    "import subprocess\n",
    "import json\n",
    "from typing import Dict\n",
    "from cfgnet.network.network_configuration import NetworkConfiguration\n",
    "from cfgnet.network.nodes import ArtifactNode\n",
    "from cfgnet.network.network import Network\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "\n",
    "def analyze_config_network(repo_path: str):\n",
    "    \n",
    "    network_config = NetworkConfiguration(\n",
    "        project_root_abs=repo_path,\n",
    "        enable_static_blacklist=False,\n",
    "        enable_internal_links=True,\n",
    "        enable_all_conflicts=True,\n",
    "        system_level=False\n",
    "    )\n",
    "\n",
    "    network = Network.init_network(cfg=network_config)\n",
    "\n",
    "    artifacts = network.get_nodes(node_type=ArtifactNode)\n",
    "\n",
    "    config_files_data = []\n",
    "    for artifact in artifacts:\n",
    "        config_files_data.append({\n",
    "            \"file_path\": artifact.rel_file_path,\n",
    "            \"options\": len(artifact.get_pairs())\n",
    "        })\n",
    "\n",
    "\n",
    "    config_files = set(artifact.rel_file_path for artifact in artifacts)\n",
    "    concepts = set(artifact.concept_name for artifact in artifacts)\n",
    "  \t\n",
    "    network_data = {\n",
    "        \"links\": len(network.links),\n",
    "        \"concepts\": concepts,\n",
    "        \"config_files\": config_files,\n",
    "        \"config_files_data\": config_files_data\n",
    "    }\n",
    "\n",
    "    return network_data\n",
    "\n",
    "\n",
    "def analyze_repository(repo_path: str, branch_name: str = \"main\") -> Dict:\n",
    "    \"\"\"Analyze Commit history of repositories and collect stats about the configuration space.\"\"\"   \n",
    "    \n",
    "    repo = git.Repo(repo_path)\n",
    "\n",
    "    # Save the current branch to return to it later\n",
    "    current_branch = repo.active_branch.name if not repo.head.is_detached else None\n",
    "    latest_commit = repo.head.commit.hexsha\n",
    "\n",
    "    # Get all commits in the repository from oldest to newest\n",
    "    commits = list(repo.iter_commits(branch_name))[::-1] \n",
    "\n",
    "    print(f\"Number of commits: {len(commits)}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    commit_data = []\n",
    "\n",
    "    for commit in commits:\n",
    "\n",
    "        # get commit stats\n",
    "        stats = commit.stats.total\n",
    "\n",
    "        # Checkout the commit\n",
    "        repo.git.checkout(commit.hexsha)\n",
    "\n",
    "        # Run the external analysis (replace with your actual command)\n",
    "        try: \n",
    "            network_data = analyze_config_network(repo_path=repo_path)\n",
    "        except Exception as error:\n",
    "            print(f\"Error occurred: {error}\")\n",
    "\n",
    "\n",
    "        # Get general stats per file\n",
    "        for file_path, file_stats in commit.stats.files.items():\n",
    "\n",
    "            if file_path in network_data[\"config_files\"]:\n",
    "\n",
    "                file_data = next(filter(lambda x: x[\"file_path\"] == file_path, network_data[\"config_files_data\"]))\n",
    "                file_data[\"insertions\"] = file_stats['insertions']\n",
    "                file_data[\"deletions\"] = file_stats['deletions']\n",
    "                file_data[\"total_changes\"] = file_stats['insertions'] + file_stats['deletions']\n",
    "\n",
    "            # Only proceed if the commit has a parent (to avoid errors on the first commit)\n",
    "            #if commit.parents:\n",
    "            #    parent_commit = f\"{commit.hexsha}^\"\n",
    "\n",
    "                #try:\n",
    "                    # Run git diff to capture line-by-line changes\n",
    "                    #diff_output = subprocess.check_output(\n",
    "                    #    ['git', 'diff', parent_commit, commit.hexsha, '--', file_path],\n",
    "                    #    cwd=repo_path,\n",
    "                    #    text=True\n",
    "                    #)\n",
    "                    #print(\"  Diff Output:\\n\", diff_output)\n",
    "\n",
    "                    # Capture file size before and after the commit\n",
    "                    #file_content_after = repo.git.show(f\"{commit.hexsha}:{file_path}\")\n",
    "                    #size_after = len(file_content_after.encode('utf-8'))\n",
    "\n",
    "                    #file_content_before = repo.git.show(f\"{parent_commit}:{file_path}\")\n",
    "                    #size_before = len(file_content_before.encode('utf-8'))\n",
    "\n",
    "                    #print(f\"  Size Before: {size_before} bytes\")\n",
    "                    #print(f\"  Size After: {size_after} bytes\")\n",
    "                    #print(f\"  Net Size Change: {size_after - size_before} bytes\")\n",
    "                \n",
    "                #except subprocess.CalledProcessError as e:\n",
    "                    #print(f\"  Error running git diff: {e}\")\n",
    "                #except git.exc.GitCommandError:\n",
    "                    #print(\"  File did not exist in previous commit (added in this commit)\")\n",
    "\n",
    "            #else:\n",
    "                #print(\"  No parent commit available (this is the first commit)\")\n",
    "\n",
    "        print(\"\\n\")\n",
    "\n",
    "        commit_data.append(\n",
    "            {\n",
    "                \"commit_hash\": str(commit.hexsha),\n",
    "                \"author\": f\"{commit.author.name} <{commit.author.email}>\",\n",
    "                \"commit_mgs\": str(commit.message),\n",
    "                \"files_changed\": stats['files'],\n",
    "                \"insertions\": stats['insertions'],\n",
    "                \"deletions\": stats['deletions'],\n",
    "                \"network_data\": network_data\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Finally, return to the latest commit\n",
    "    if current_branch:\n",
    "        # If we were on a branch, return to it\n",
    "        repo.git.checkout(current_branch)\n",
    "        print(f\"Returned to original branch: {current_branch}\")\n",
    "    else:\n",
    "        # If we were in a detached HEAD state, checkout the latest commit directly\n",
    "        repo.git.checkout(latest_commit)\n",
    "        print(f\"Returned to the latest commit: {latest_commit}\")\n",
    "\n",
    "    for x in commit_data:\n",
    "        pprint(x)\n",
    "\n",
    "    with open(\"../data/test_project_data.json\", \"w\", encoding=\"utf-8\") as dest:\n",
    "        json.dump(commit_data, dest, indent=2)\n",
    "\n",
    "test_repo_path = \"/home/ssimon/github/config_project\"\n",
    "\n",
    "stats = analyze_repository(repo_path=test_repo_path, branch_name=\"master\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
