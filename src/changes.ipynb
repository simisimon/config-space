{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract co-changes across the commit history**\n",
    "\n",
    "- co-changes of concepts\n",
    "- co-changest of config file\n",
    "- co-changes of config options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis import analyze_repository\n",
    "import json\n",
    "\n",
    "repo_path = \"/home/ssimon/projects/test-config-repo\"\n",
    "output_file = \"../data/analyzed_projects/test-config-repo.json\"\"../data/analyzed_projects/test-config-repo.json\"\n",
    "commit_data = analyze_repository(repo_path=repo_path, project_name=\"test-config-repo\", get_diff=True)\n",
    "\n",
    "# Store commit data into the output file\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as dest:\n",
    "    json.dump(commit_data, dest, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute Co-Changed Concepts (Internally)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "import glob\n",
    "\n",
    "def extract_concept_cochanges(file_path: str, repo_name: str):\n",
    "    print(\"Extract concept co-changes from\", repo_name)\n",
    "\n",
    "    # Load the JSON file\n",
    "    with open(file_path) as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Counter to store co-changes\n",
    "    concept_counts = Counter()\n",
    "\n",
    "    # Process each commit\n",
    "    for commit in data.get('config_commit_data', []):\n",
    "        \n",
    "        # Skip if no network data\n",
    "        if not commit.get('network_data'):\n",
    "            continue\n",
    "\n",
    "        concepts = commit['network_data'].get('concepts', [])\n",
    "      \n",
    "        # Generate pairs of technologies and pairs of files\n",
    "        pairs = [tuple(sorted(pair)) for pair in combinations(concepts, 2)]\n",
    "        \n",
    "        # Count each pair\n",
    "        concept_counts.update(pairs)\n",
    "\n",
    "\n",
    "    # Prepare DataFrame data\n",
    "    concept_rows = []\n",
    "    for (concept1, concept2), count in concept_counts.items():\n",
    "        concept_rows.append({\n",
    "            \"Co-Changed Concepts\": (concept1, concept2),\n",
    "            \"Concept1\": concept1,\n",
    "            \"Concept2\": concept2,\n",
    "            \"Changed Internally\": count,\n",
    "            \"Percentage Internally\": round(count / len(data['config_commit_data']), 2)\n",
    "        })\n",
    "\n",
    "    concept_df = pd.DataFrame(concept_rows)\n",
    "\n",
    "    concept_df.to_csv(f\"../data/concept_cochanges/{repo_name}_concept_cochanges.csv\", index=False)\n",
    "\n",
    "\n",
    "for file_path in glob.glob(f\"../data/analyzed_projects/**\"):\n",
    "    file_name = file_path.split(\"/\")[-1].split(\".\")[0]\n",
    "    extract_concept_cochanges(file_path, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute Co-Changed Concepts (Globally)**\n",
    "\n",
    "Definitions of columns\n",
    "- `Across Projects` is an integer, indicating number of projects where the co-changed concepts changed as well at least once\n",
    "- `Percentage globally` is an float, indicating the percentage of projects where the co-changed concepts changed as well\n",
    "- `Changed globally` is an integer, indicating the total number of times the co-changed concepts changed in other projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_cochanged_concepts(target_df, other_dfs):\n",
    "    \"\"\"\n",
    "    Analyze co-changed concepts in a target file against all other projects to compute global stats.\n",
    "\n",
    "    :param target_df: dataframe of target project\n",
    "    :param other_dfs: dataframes of all other projects\n",
    "    :return target_df: updated dataframe of target project\n",
    "    \"\"\"\n",
    "    # Initialize columns\n",
    "    target_df['Across Projects'] = 0 # Number of projects where the co-changed concepts changed as well at lea\n",
    "    target_df['Percentage globally'] = 0 # Percentage of projects where the co-changed concepts changed as well\n",
    "    target_df['Changed globally'] = 0 # Totoal number of times the co-changed concepts changed in other projects\n",
    "\n",
    "    for index, row in target_df.iterrows():\n",
    "        concepts = row['Co-Changed Concepts']\n",
    "\n",
    "        for other_df in other_dfs:\n",
    "            # Find all rows in other_df where the option matches\n",
    "            matching_rows = other_df[other_df['Co-Changed Concepts'] == concepts]\n",
    "            match_count = len(matching_rows)\n",
    "\n",
    "            if match_count > 0:\n",
    "                # Increment \"Across Projects\" by 1 (project-level count)\n",
    "                target_df.loc[index, 'Across Projects'] += 1\n",
    "\n",
    "                # Increment \"Changed globally\" by the number of times the concepts changed\n",
    "                target_df.loc[index, 'Changed globally'] += match_count\n",
    "\n",
    "    target_df['Percentage globally'] = round(target_df['Across Projects'] / len(other_dfs), 2)     \n",
    "\n",
    "    return target_df\n",
    "\n",
    "\n",
    "data_dir = \"../data/concept_cochanges\"\n",
    "\n",
    "# Load all CSV files from the directory into a dictionary of DataFrames\n",
    "repository_files = [file for file in os.listdir(data_dir) if file.endswith('.csv')]\n",
    "repository_dataframes = {file: pd.read_csv(os.path.join(data_dir, file)) for file in repository_files}\n",
    "\n",
    "target_repo = \"piggymetrics\"\n",
    "target_file_name = f'{target_repo}_concept_cochanges.csv'\n",
    "target_df = repository_dataframes[target_file_name]\n",
    "\n",
    "# Use all other files as comparison\n",
    "other_dfs = [df for name, df in repository_dataframes.items() if name != target_file_name]\n",
    "\n",
    "# Perform the analysis\n",
    "updated_target_df = get_cochanged_concepts(target_df.copy(), other_dfs)\n",
    "\n",
    "updated_target_df.head(50)\n",
    "\n",
    "updated_target_df.to_csv(f\"../data/concept_cochanges/{target_repo}_concept_cochanges.csv\")\n",
    "\n",
    "updated_target_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute co-changed config files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "import glob\n",
    "\n",
    "\n",
    "def extract_file_cochanges(file_path: str, repo_name: str):\n",
    "    print(\"Extract file co-changes from\", repo_name)\n",
    "    \n",
    "    # Load the JSON file\n",
    "    with open(file_path) as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Counter to store co-changes\n",
    "    file_pair_counts = Counter()\n",
    "\n",
    "    # Process each commit\n",
    "    for commit in data.get('config_commit_data', []):\n",
    "\n",
    "        # Skip if no network data\n",
    "        if not commit.get('network_data'):\n",
    "            continue\n",
    "\n",
    "        config_files = commit['network_data'].get('config_files', [])\n",
    "\n",
    "        # Generate pairs of files\n",
    "        file_pairs = [tuple(sorted(pair)) for pair in combinations(config_files, 2)]\n",
    "        \n",
    "        # Count each pair\n",
    "        file_pair_counts.update(file_pairs)\n",
    "\n",
    "    # Prepare DataFrame data\n",
    "    file_rows = []\n",
    "    for (file1, file2), count in file_pair_counts.items():\n",
    "        file_rows.append({\n",
    "            \"Co-Changed Artifacts\": (file1, file2),\n",
    "            \"Artifact1\": file1,\n",
    "            \"Artifact2\": file2,\n",
    "            \"Changed Internally\": count,\n",
    "            \"Percentage Internally\": round(count / len(data['config_commit_data']), 2)\n",
    "        })\n",
    "\n",
    "    file_df = pd.DataFrame(file_rows)\n",
    "\n",
    "    file_df.to_csv(f\"../data/file_cochanges/{repo_name}_file_cochanges.csv\", index=False)\n",
    "\n",
    "for file_path in glob.glob(f\"../data/analyzed_projects/**\"):\n",
    "    file_name = file_path.split(\"/\")[-1].split(\".\")[0]\n",
    "    extract_file_cochanges(file_path, file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute Co-Changed Config Files (Globally)**\n",
    "\n",
    "Definitions of columns\n",
    "- `Across Projects` is an integer, indicating number of projects where the co-changed artifacts changed as well at least once\n",
    "- `Percentage globally` is an float, indicating the percentage of projects where the co-changed artifacts changed as well\n",
    "- `Changed globally` is an integer, indicating the total number of times the co-changed artifacts changed in other projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_cochanged_artifacts(target_df, other_dfs):\n",
    "    \"\"\"\n",
    "    Analyze co-changed artifacts in a target file against all other projects to compute global stats.\n",
    "\n",
    "    :param target_df: dataframe of target project\n",
    "    :param other_dfs: dataframes of all other projects\n",
    "    :return target_df: updated dataframe of target project\n",
    "    \"\"\"\n",
    "    # Initialize columns\n",
    "    target_df['Across Projects'] = 0\n",
    "    target_df['Changed globally'] = 0\n",
    "\n",
    "    for index, row in target_df.iterrows():\n",
    "        artifacts = row['Co-Changed Artifacts']\n",
    "\n",
    "        for other_df in other_dfs:\n",
    "            # Find all rows in other_df where the option matches\n",
    "            matching_rows = other_df[other_df['Co-Changed Artifacts'] == artifacts]\n",
    "            match_count = len(matching_rows)\n",
    "\n",
    "            if match_count > 0:\n",
    "                # Increment \"Across Projects\" by 1 (project-level count)\n",
    "                target_df.loc[index, 'Across Projects'] += 1\n",
    "\n",
    "                # Increment \"Changed globally\" by the number of times the artifacts changed\n",
    "                target_df.loc[index, 'Changed globally'] += match_count\n",
    "\n",
    "    target_df['Percentage globally'] = round(target_df['Across Projects'] / len(other_dfs), 2)     \n",
    "\n",
    "    return target_df\n",
    "\n",
    "\n",
    "data_dir = \"../data/file_cochanges\"\n",
    "\n",
    "# Load all CSV files from the directory into a dictionary of DataFrames\n",
    "repository_files = [file for file in os.listdir(data_dir) if file.endswith('.csv')]\n",
    "repository_dataframes = {file: pd.read_csv(os.path.join(data_dir, file)) for file in repository_files}\n",
    "\n",
    "target_repo = \"test-config-repo\"\n",
    "target_file_name = f'{target_repo}_file_cochanges.csv'\n",
    "target_df = repository_dataframes[target_file_name]\n",
    "\n",
    "# Use all other files as comparison\n",
    "other_dfs = [df for name, df in repository_dataframes.items() if name != target_file_name]\n",
    "\n",
    "# Perform the analysis\n",
    "updated_target_df = get_cochanged_artifacts(target_df.copy(), other_dfs)\n",
    "\n",
    "updated_target_df.head(50)\n",
    "\n",
    "updated_target_df.to_csv(f\"../data/file_cochanges/{target_repo}_file_cochanges.csv\")\n",
    "\n",
    "updated_target_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute co-changed config options**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "import glob\n",
    "\n",
    "def extract_option_cochanges(file_path: str, repo_name: str):\n",
    "    print(\"Extract option co-changes from\", repo_name)\n",
    "\n",
    "    # Load the JSON file\n",
    "    with open(file_path) as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Counter to store co-changes\n",
    "    option_pair_counts = Counter()\n",
    "\n",
    "    # Process each commit\n",
    "    for commit in data.get('config_commit_data', []):    \n",
    "        modified_options = {}\n",
    "        \n",
    "        # Skip if no network data\n",
    "        if not commit.get('network_data'):\n",
    "            continue\n",
    "\n",
    "        # Collect options from all files in this commit\n",
    "        for file_data in commit['network_data'].get('config_files_data', []):\n",
    "            for pair in file_data.get('modified_pairs', []):\n",
    "                modified_options[pair['option']] = pair\n",
    "\n",
    "        # Generate unique pairs of modified options (by option name)\n",
    "        option_names = list(modified_options.keys())\n",
    "        option_pairs = [tuple(sorted(pair)) for pair in combinations(option_names, 2)]\n",
    "\n",
    "        # Count occurrences of each pair and retain full details\n",
    "        for option1, option2 in option_pairs:\n",
    "            pair_details = (\n",
    "                tuple(sorted(modified_options[option1].items())),\n",
    "                tuple(sorted(modified_options[option2].items()))\n",
    "            )\n",
    "            option_pair_counts[pair_details] += 1\n",
    "\n",
    "    # Prepare DataFrame data\n",
    "    rows = []\n",
    "    for (option1_details, option2_details), count in option_pair_counts.items():\n",
    "        # Extract details for Option1 and Option2\n",
    "        opt1 = dict(option1_details)\n",
    "        opt2 = dict(option2_details)\n",
    "        rows.append({\n",
    "            \"Co-Changed Options\": (opt1.get('option'), opt2.get('option')),\n",
    "            \"Option1\": opt1.get(\"option\"),\n",
    "            \"Values1\": (opt1.get(\"prev_value\"), opt1.get(\"curr_value\")),\n",
    "            \"Artifact1\": opt1.get(\"artifact\"),\n",
    "            \"Option2\": opt2.get(\"option\"),\n",
    "            \"Values2\": (opt2.get(\"prev_value\"), opt2.get(\"curr_value\")),\n",
    "            \"Artifact2\": opt2.get(\"artifact\"),\n",
    "            \"Changed Internally\": count,\n",
    "            \"Percentage Internally\": count / len(data['config_commit_data'])\n",
    "        })\n",
    "\n",
    "    # Create DataFrame\n",
    "    option_df = pd.DataFrame(rows)\n",
    "\n",
    "    option_df.to_csv(f\"../data/option_cochanges/{repo_name}_option_cochanges.csv\", index=False)\n",
    "\n",
    "\n",
    "for file_path in glob.glob(f\"../data/analyzed_projects/**\"):\n",
    "    file_name = file_path.split(\"/\")[-1].split(\".\")[0]\n",
    "    extract_option_cochanges(file_path, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute Co-Changed Options (Globally)**\n",
    "\n",
    "Definitions of columns\n",
    "- `Across Projects` is an integer, indicating number of projects where the co-changed options changed as well at least once\n",
    "- `Percentage globally` is an float, indicating the percentage of projects where the co-changed options changed as well\n",
    "- `Changed globally` is an integer, indicating the total number of times the co-changed options changed in other projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def get_cochanged_options(target_df, other_dfs):\n",
    "    \"\"\"\n",
    "    Analyze co-changed options in a target file against all other projects to compute global stats.\n",
    "\n",
    "    :param target_df: dataframe of target project\n",
    "    :param other_dfs: dataframes of all other projects\n",
    "    :return target_df: updated dataframe of target project\n",
    "    \"\"\"\n",
    "    # Initialize columns\n",
    "    target_df['Across Projects'] = 0\n",
    "    target_df['Changed globally'] = 0\n",
    "\n",
    "    for index, row in target_df.iterrows():\n",
    "        options = row['Co-Changed Options']\n",
    "\n",
    "        for other_df in other_dfs:\n",
    "            # Find all rows in other_df where the option matches\n",
    "            matching_rows = other_df[other_df['Co-Changed Options'] == options]\n",
    "            match_count = len(matching_rows)\n",
    "\n",
    "            if match_count > 0:\n",
    "                # Increment \"Across Projects\" by 1 (project-level count)\n",
    "                target_df.loc[index, 'Across Projects'] += 1\n",
    "\n",
    "                # Increment \"Changed globally\" by the total count of matches\n",
    "                target_df.loc[index, 'Changed globally'] += match_count\n",
    "\n",
    "    target_df['Percentage globally'] = round(target_df['Across Projects'] / len(other_dfs), 2)     \n",
    "\n",
    "    return target_df\n",
    "\n",
    "\n",
    "data_dir = \"../data/option_cochanges\"\n",
    "\n",
    "# Load all CSV files from the directory into a dictionary of DataFrames\n",
    "repository_files = [file for file in os.listdir(data_dir) if file.endswith('.csv')]\n",
    "repository_dataframes = {file: pd.read_csv(os.path.join(data_dir, file)) for file in repository_files}\n",
    "\n",
    "target_repo = \"mall\"\n",
    "target_file_name = f'{target_repo}_option_cochanges.csv'\n",
    "target_df = repository_dataframes[target_file_name]\n",
    "\n",
    "# Use all other files as comparison\n",
    "other_dfs = [df for name, df in repository_dataframes.items() if name != target_file_name]\n",
    "\n",
    "# Perform the analysis\n",
    "updated_target_df = get_cochanged_options(target_df.copy(), other_dfs)\n",
    "\n",
    "updated_target_df.head(50)\n",
    "\n",
    "updated_target_df.to_csv(f\"../data/option_cochanges/{target_repo}_option_cochanges.csv\")\n",
    "\n",
    "updated_target_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
