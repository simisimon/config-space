{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "# base url\n",
    "BASE_URL = \"https://api.github.com/search/repositories\"\n",
    "\n",
    "# GitHub personal access token (replace with your token)\n",
    "TOKEN = os.getenv(\"GITHUB_TOKEN\")\n",
    "\n",
    "# Set up headers with authentication token\n",
    "headers = {\n",
    "    'Authorization': f'token {TOKEN}'\n",
    "}\n",
    "\n",
    "# Function to fetch repositories with retry logic\n",
    "def fetch_repositories():\n",
    "    repositories = []\n",
    "    page = 11\n",
    "    per_page = 100  # Maximum allowed per page\n",
    "    retries = 0\n",
    "    max_retries = 5\n",
    "    backoff_factor = 2  # Exponential backoff\n",
    "\n",
    "    while len(repositories) < 10000:\n",
    "        params = {\n",
    "            'q': 'stars:>0',  # Filter to get repos with at least 1 star\n",
    "            'sort': 'stars',\n",
    "            'order': 'desc',\n",
    "            'per_page': per_page,\n",
    "            'page': page\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.get(BASE_URL, headers=headers, params=params)\n",
    "\n",
    "            # Check for secondary rate limit\n",
    "            if response.status_code == 403 and \"secondary rate limit\" in response.text.lower():\n",
    "                print(\"Hit secondary rate limit. Waiting before retrying...\")\n",
    "                retries += 1\n",
    "                if retries > max_retries:\n",
    "                    print(\"Max retries reached. Exiting.\")\n",
    "                    break\n",
    "                wait_time = backoff_factor ** retries\n",
    "                print(f\"Retrying after {wait_time} seconds...\")\n",
    "                time.sleep(wait_time)\n",
    "                continue\n",
    "\n",
    "            # Check for other errors\n",
    "            if response.status_code != 200:\n",
    "                print(f\"Error: {response.status_code}, {response.json()}\")\n",
    "                break\n",
    "\n",
    "            # Reset retries if successful\n",
    "            retries = 0\n",
    "\n",
    "            data = response.json()\n",
    "            repos = data.get('items', [])\n",
    "            repositories.extend(repos)\n",
    "\n",
    "            if len(repos) == 0:\n",
    "                break  # Stop if no more repositories are returned\n",
    "\n",
    "            print(f\"Fetched {len(repositories)} repositories so far on page {page} ... \")\n",
    "\n",
    "            page += 1\n",
    "\n",
    "            # Respect GitHub's rate limits by sleeping for a short time\n",
    "            time.sleep(2)\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            break\n",
    "\n",
    "    return repositories[:10000]\n",
    "\n",
    "# Fetch the top 10,000 repositories\n",
    "top_repositories = fetch_repositories()\n",
    "\n",
    "names = []\n",
    "full_names = []\n",
    "urls = []\n",
    "stars = []\n",
    "descriptions = []\n",
    "\n",
    "# Output the top repositories\n",
    "for repo in top_repositories:\n",
    "    names.append(repo['name'])\n",
    "    full_names.append(repo[\"full_name\"])\n",
    "    stars.append(repo[\"stargazers_count\"])\n",
    "    urls.append(repo[\"html_url\"])\n",
    "    descriptions.append(repo[\"description\"])\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"stars\"] = stars\n",
    "df[\"name\"] = names\n",
    "df[\"full_name\"] = full_names\n",
    "df[\"description\"] = descriptions\n",
    "df[\"url\"] = urls\n",
    "\n",
    "df.to_csv(\"projects.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "# base url\n",
    "BASE_URL = \"https://api.github.com/search/repositories\"\n",
    "\n",
    "# GitHub personal access token (replace with your token)\n",
    "TOKEN = os.getenv(\"GITHUB_TOKEN\")\n",
    "\n",
    "# Set up headers with authentication token\n",
    "headers = {\n",
    "    'Authorization': f'token {TOKEN}'\n",
    "}\n",
    "\n",
    "# Function to fetch repositories for a given star range\n",
    "def fetch_repositories_by_stars(min_stars, max_stars):\n",
    "    repositories = []\n",
    "    page = 1\n",
    "    per_page = 100  # Maximum allowed per page\n",
    "\n",
    "    while True:\n",
    "        params = {\n",
    "            'q': f'stars:{min_stars}..{max_stars}',\n",
    "            'sort': 'stars',\n",
    "            'order': 'desc',\n",
    "            'per_page': per_page,\n",
    "            'page': page\n",
    "        }\n",
    "\n",
    "        response = requests.get(BASE_URL, headers=headers, params=params)\n",
    "\n",
    "        # Check for errors\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error: {response.status_code}, {response.json()}\")\n",
    "            break\n",
    "\n",
    "        data = response.json()\n",
    "        repos = data.get('items', [])\n",
    "        repositories.extend(repos)\n",
    "\n",
    "        if len(repos) == 0 or len(repositories) >= 10000:\n",
    "            break  # Stop if no more repositories are returned or we hit the 10,000 limit\n",
    "\n",
    "        print(f\"Fetched {len(repositories)} repositories with {min_stars}..{max_stars} stars...\")\n",
    "\n",
    "        page += 1\n",
    "\n",
    "        # Respect GitHub's rate limits by sleeping for a short time\n",
    "        time.sleep(2)\n",
    "\n",
    "    return repositories\n",
    "\n",
    "# Function to fetch the top 10,000 repositories by splitting star ranges\n",
    "def fetch_top_repositories():\n",
    "    repositories = []\n",
    "    star_ranges = [\n",
    "        (100000, 500000),  # Repositories with 500,000 to 100,000 stars\n",
    "        (50000, 100000),  # Repositories with 50,000 to 100,000 stars\n",
    "        (40000, 50000),   # Repositories with 40,000 to 50,000 stars\n",
    "        (30000, 40000),   # Repositories with 30,000 to 40,000 stars\n",
    "        (20000, 30000),   # Repositories with 20,000 to 30,000 stars\n",
    "        (10000, 20000),   # Repositories with 10,000 to 20,000 stars\n",
    "        (5000, 10000),    # Repositories with 5,000 to 10,000 stars\n",
    "        (1000, 5000),     # Repositories with 1,000 to 5,000 stars\n",
    "        (500, 1000),      # Repositories with 500 to 1,000 stars\n",
    "    ]\n",
    "\n",
    "    for min_stars, max_stars in star_ranges:\n",
    "        if len(repositories) >= 10000:\n",
    "            break\n",
    "\n",
    "        # Fetch repositories within the star range\n",
    "        repos = fetch_repositories_by_stars(min_stars, max_stars)\n",
    "        repositories.extend(repos)\n",
    "\n",
    "        # Stop once we've hit 10,000 repositories\n",
    "        if len(repositories) >= 10000:\n",
    "            break\n",
    "\n",
    "    return repositories[:10000]\n",
    "\n",
    "# Fetch the top 10,000 repositories\n",
    "top_repositories = fetch_top_repositories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len repos:  5409\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/projects.csv\")\n",
    "\n",
    "print(\"Len repos: \", len(df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
